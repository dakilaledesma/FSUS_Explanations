{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dakilaledesma/FSUS_Explanations/blob/main/notebooks/train/Sequencer2D_Q600G4F15.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4RBv2CGN3gJv",
        "outputId": "d9aafb26-c58a-4a66-82e7-afb364972f13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 504 ms, sys: 97 ms, total: 601 ms\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "! unzip -q drive/MyDrive/UNC/S2022P/GBIF_Q_fourth15.zip -d /content/temp\n",
        "! mv /content/temp/content/dataset/train /content/train\n",
        "! rm -rf /content/temp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXOHMDgapMby",
        "outputId": "7bd1c733-b7ef-4876-81a8-2a5df409f474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'pytorch-image-models'...\n",
            "remote: Enumerating objects: 10858, done.\u001b[K\n",
            "remote: Counting objects: 100% (385/385), done.\u001b[K\n",
            "remote: Compressing objects: 100% (194/194), done.\u001b[K\n",
            "remote: Total 10858 (delta 226), reused 277 (delta 182), pack-reused 10473\u001b[K\n",
            "Receiving objects: 100% (10858/10858), 20.48 MiB | 16.91 MiB/s, done.\n",
            "Resolving deltas: 100% (7941/7941), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/rwightman/pytorch-image-models.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "slckThLBilky"
      },
      "outputs": [],
      "source": [
        "import fileinput\n",
        "import sys\n",
        "\n",
        "def replacement(file, previousw, nextw):\n",
        "   for line in fileinput.input(file, inplace=1):\n",
        "       line = line.replace(previousw, nextw)\n",
        "       sys.stdout.write(line)\n",
        "\n",
        "file = \"/content/pytorch-image-models/timm/utils/checkpoint_saver.py\"\n",
        "replacement(file, \"if os.path.exists(last_save_path):\", \"# if os.path.exists(last_save_path):\")\n",
        "replacement(file, \"os.unlink(last_save_path)  # required for Windows support.\", \"# os.unlink(last_save_path)  # required for Windows support.\")\n",
        "replacement(file, \"os.link(last_save_path, save_path)\", \"# os.link(last_save_path, save_path)\")\n",
        "replacement(file, \"os.unlink(best_save_path)\", \"# os.unlink(best_save_path)\")\n",
        "replacement(file, \"os.link(last_save_path, best_save_path)\", \"# os.link(last_save_path, best_save_path)\")\n",
        "replacement(file, \"if os.path.exists(best_save_path):\", \"# if os.path.exists(best_save_path):\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2bjHJwMfqlJ",
        "outputId": "5ee8251c-ad42-4826-8524-c2eb5f127e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "57\n"
          ]
        }
      ],
      "source": [
        "from glob import glob\n",
        "\n",
        "print(len(list(glob(\"train/*\"))))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kIBgHy6pSFD",
        "outputId": "ac2ffc31-45b9-45f0-b830-662d76c439be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py:186: FutureWarning: The module torch.distributed.launch is deprecated\n",
            "and will be removed in future. Use torchrun.\n",
            "Note that --use_env is set by default in torchrun.\n",
            "If your script expects `--local_rank` argument to be set, please\n",
            "change it to read from `os.environ['LOCAL_RANK']` instead. See \n",
            "https://pytorch.org/docs/stable/distributed.html#launch-utility for \n",
            "further instructions\n",
            "\n",
            "  FutureWarning,\n",
            "Training with a single process on 1 GPUs.\n",
            "Loading pretrained weights from url (https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth)\n",
            "Downloading: \"https://github.com/okojoalg/sequencer/releases/download/weights/sequencer2d_l.pth\" to /root/.cache/torch/hub/checkpoints/sequencer2d_l.pth\n",
            "Model sequencer2d_l created, param count:53935161\n",
            "Data processing configuration for current model + dataset:\n",
            "\tinput_size: (3, 600, 600)\n",
            "\tinterpolation: bicubic\n",
            "\tmean: (0.485, 0.456, 0.406)\n",
            "\tstd: (0.229, 0.224, 0.225)\n",
            "\tcrop_pct: 0.875\n",
            "Using native Torch AMP. Training in mixed precision.\n",
            "Scheduled epochs: 80\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:566: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Train: 0 [   0/12946 (  0%)]  Loss: 4.043 (4.04)  Time: 8.793s,    0.91/s  (8.793s,    0.91/s)  LR: 1.000e-04  Data: 2.191 (2.191)\n"
          ]
        }
      ],
      "source": [
        "! python -u -m torch.distributed.launch --nproc_per_node=1 --nnodes=1 --node_rank=0 ./pytorch-image-models/train.py train --model sequencer2d_l --opt adabelief --lr 0.00005 --epochs 80 --aa augmix-m5-w4 --aug-splits 2 --jsd-loss --decay-epochs 3 --cooldown-epochs 0 --weight-decay 1e-4 --sched cosine -b 4 --input-size 3 600 600 --num-classes=57 --vflip 0.5 --hflip 0.5 --amp --pretrained --output drive/MyDrive/UNC/S2022P/output/ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMHrwfTNvpQI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "[FSUS] Sequencer2D-Q600G4F15",
      "provenance": [],
      "mount_file_id": "1wQgJEW6GKlGJkBjJR-YvUO9oARc98FX0",
      "authorship_tag": "ABX9TyPD6f6TIb4wnOjCd/oInwWG",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}